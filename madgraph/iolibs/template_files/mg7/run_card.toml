[run]
run_name = "run"
device = "cpu" # cuda, hip, cpp, cppnone, cppsse4, cppavx2, cpp512y, cpp512z, cppauto
simd_vector_size = -1
thread_pool_size = -1 # -1 sets count automatically based on number of CPUs
output_format = "lhe" # options: compact_npy, lhe_npy, lhe
verbosity = "pretty" # options: silent, pretty, log
dummy_matrix_element = false

[beam]
e_cm = 13000.0
leptonic = false
pdf = "NNPDF23_lo_as_0130_qed"
fixed_ren_scale = true
fixed_fact_scale = true
ren_scale = 91.188
fact_scale1 = 91.188
fact_scale2 = 91.188
# options: transverse_energy, transverse_mass, half_transverse_mass, partonic_energy
dynamical_scale_choice = "half_transverse_mass"

[generation]
events = 10000
max_overweight_truncation = 0.01
freeze_max_weight_after = 10000
batch_size = 1000
survey_min_iters = 3
survey_max_iters = 3
survey_target_precision = 0.1

[vegas]
enable = true
bins = 64
damping = 0.4
optimization_patience = 5
optimization_threshold = 0.9
start_batch_size = 1000
max_batch_size = 32000

[phasespace]
mode = "both" #options: multichannel, flat, both
sde_strategy = "diagrams" #options: diagrams, denominators
decays = "all" # options: all, massive, none
t_channel = "propagator" # options: propagator, rambo, chili
flat_mode = "rambo" # options: propagator, rambo, chili
simplified_channel_count = 10
invariant_power = 0.7
bw_cutoff = 15

[multiparticles]
jet = [1, 2, 3, 4, -1, -2, -3, -4, 21]
bottom = [-5, 5]
lepton = [11, 13, 15, -11, -13, -15]
missing = [12, 14, 16, -12, -14, -16]
photon = [22]

[cuts]
# possible groups: jet, bottom, lepton, missing, photon
# possible observables: pt, eta, dR, mass, sqrt_s
#     (mass is for pairs of particles from the same group, sqrt_s is for all outgoing particles)
# for all cuts, min or max can be specified

jet-pt.min = 20.0
jet-eta_abs.max = 5.0
jet-delta_r.min = 0.4

lepton-pt.min = 10.0
lepton-eta_abs.max = 2.5
lepton-delta_r.min = 0.4

jet-lepton-delta_r.min=0.4

sqrt_s.min = 0.0

[histograms]


[madnis]
enable = false

# normalizing flow parameters
flow_hidden_dim = 64
flow_layers = 3
flow_spline_bins = 10
flow_activation = "leaky_relu" # options: relu, leaky_relu, elu, gelu, sigmoid, softplus
flow_invert_spline = false

# discrete dimensions
discrete_hidden_dim = 64
discrete_layers = 3
discrete_activation = "leaky_relu" # options: relu, leaky_relu, elu, gelu, sigmoid, softplus

# channel weight network
cwnet_hidden_dim = 64
cwnet_layers = 3
cwnet_activation = "leaky_relu" # options: relu, leaky_relu, elu, gelu, sigmoid, softplus

# training parameters
loss = "stratified_variance" # options: stratified_variance, kl_divergence, rkl_divergence
train_batches = 1000
log_interval = 100
batch_size_offset = 512
batch_size_per_channel = 128
lr = 1e-3
lr_decay = 0.01
lr_max = 3e-3
lr_scheduler = "cosine" # options: exponential, inverse, onecycle, cosine, none
train_mcw = true
buffer_capacity = 0
minimum_buffer_size = 50000
buffered_steps = 0
uniform_channel_ratio = 0.1
integration_history_length = 1000
max_stored_channel_weights = 100
channel_dropping_threshold = 0.01
channel_dropping_interval = 200
drop_zero_integrands = true
batch_size_threshold = 0.5
channel_grouping_mode = "uniform" # options: none, uniform, learned
fixed_cwnet_fraction = 0.33
